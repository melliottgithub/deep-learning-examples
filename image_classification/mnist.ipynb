{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1BMmhrW4-VF"
      },
      "source": [
        "# A tutorial introduction into deep learning with Keras and Tensorflow.  We will use the MNIST dataset which is the 'Hello world' problem of deep learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfjjxqk-4-VY"
      },
      "source": [
        "I always like to start my jupyter notebooks with this code because it fits the display window to my screen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "oq3zQaj94-Vf",
        "outputId": "a15f92ac-6915-46cf-bb36-b7ed109c222b"
      },
      "outputs": [],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTIiJaMH4-We"
      },
      "source": [
        "### This tutorial was adapted from Deep Learning with Python Chollet, F. (2021). Deep Learning with Python (2nd ed.). Greenwich, CT, USA: Manning Publications Co."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7J8caRE4-Wv"
      },
      "source": [
        "Start with some definitions.\n",
        "Numerical data in an array are called [tensors](https://en.wikipedia.org/wiki/Tensor)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYhqLSfB4-W5"
      },
      "source": [
        "Scalars are 0-dimensional tensors (a single digit)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sq1dfmTjXx1r",
        "outputId": "4ea0ead6-179b-47c5-cd28-10f3d8bd9be7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "x = np.array(12)\n",
        "print('The value of x is', x)\n",
        "print('The dimension of this tensor is', x.ndim) # 0 dimensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd6j127g4-Xg"
      },
      "source": [
        "A 1-dimensional tensor is also called a vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iWxjAcgYF2H",
        "outputId": "04b70c0f-24a4-4e3b-923d-2c1eeccff972"
      },
      "outputs": [],
      "source": [
        "x = np.array([12, 1, 2, 3]) #create a vector\n",
        "print('The value of x is', x)\n",
        "print('The dimention of this tensor is', x.ndim) # 1 dimensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZnkKqX74-YS"
      },
      "source": [
        "A 2-dimensional tensor is also called a matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kw6vcniRYMga",
        "outputId": "9779c7f5-7e89-4926-8067-b18d02cd3aae"
      },
      "outputs": [],
      "source": [
        "x = np.array([[12, 1, 2, 3],\n",
        "              [5, 6, 7, 8,],\n",
        "              [10, 11, 12, 12]])\n",
        "print('The value of x is', x) # Print the 3 x 4 matrix\n",
        "print('The dimension of this tensor is', x.ndim) # 2 dimensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDXBkNgF4-ZH"
      },
      "source": [
        "We can create n-dimensional tensors easily, although they become difficult to visualize.\n",
        "This 3D tensor is like a cube of data.\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7unoEvdhYbYR",
        "outputId": "15e3f317-2cbb-4517-eebf-202f65e3483b"
      },
      "outputs": [],
      "source": [
        "x = np.array([[[12, 1, 2, 3],\n",
        "               [5, 6, 7, 8,],\n",
        "               [10, 11, 12, 12]],\n",
        "              [[2, 2, 2, 2,],\n",
        "               [3,3,3,3],\n",
        "               [4,4,4,4]],\n",
        "              [[5,5,5,5],\n",
        "               [6,6,6,6],\n",
        "               [7,7,7,7]]])\n",
        "print('The value of x is', x)\n",
        "print('The dimension of this tensor is', x.ndim) # 3 dimensional array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QrNkyOM4-Z0"
      },
      "source": [
        "#### Reshaping tensors is an important concept to understand.  We can reshape a tensor as long as it has the same number of elements as the initial tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5jul5ly4-Z6",
        "outputId": "0b6c3665-67a2-48ae-812f-94c75ba23f7d"
      },
      "outputs": [],
      "source": [
        "x = x.reshape(3*3*4,1)\n",
        "print(x)\n",
        "x = x.reshape(4, 3*3)\n",
        "print(x)\n",
        "x = x.reshape(2, 18)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihVQabEo4-aS"
      },
      "source": [
        "##### Tensors have three attributes:\n",
        "- Number of axes (dimensions)\n",
        "- Shape (length of each axis)\n",
        "- Data type (typically we will use `float32`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2vP9ckYvLuh"
      },
      "source": [
        "We can also manipulate tensors with TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XE9M6y1vULu"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "for device in tf.config.list_physical_devices():\n",
        "    print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diW1WriOvbms",
        "outputId": "3404eb34-1809-43ce-8fb3-fa47819953f7"
      },
      "outputs": [],
      "source": [
        "x = tf.ones(shape=(2,1))\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMv_KG8pv6iq",
        "outputId": "e4cf481c-2b5c-4ad4-daa9-50561eaf77f8"
      },
      "outputs": [],
      "source": [
        "# Create a Tensorflow variable\n",
        "v = tf.Variable(initial_value=tf.random.normal(shape=(3,1)))\n",
        "print(v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iljsFGcewSIE",
        "outputId": "bb1340f8-bf6a-490d-c93d-e7db4245b030"
      },
      "outputs": [],
      "source": [
        "# Once the variable is created it can be modified using assign\n",
        "v2 = v.assign(tf.random.normal(shape=(3,1)))\n",
        "print(v2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGkCIydvw2Ks"
      },
      "outputs": [],
      "source": [
        "# Now we can perform some math operations on the tensors\n",
        "# np.dot(v, v2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdzH71UFxQ2Q",
        "outputId": "e72c1d26-74a4-4cb7-c8a7-4b0bbbf71863"
      },
      "outputs": [],
      "source": [
        "# We get the above error because the shapes of v and v2 do not align properly for a dot product.\n",
        "print(v.shape)\n",
        "print(v2.shape)\n",
        "\n",
        "# For a dot product to alight the column rows of X must match the rows of Y. (See Figure 2.5 in book)\n",
        "# Therefore, we must transpose v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSctb3a0x8l-",
        "outputId": "7e3ade69-0df3-4b71-c04d-c512cf3bfa29"
      },
      "outputs": [],
      "source": [
        "v3 = np.transpose(v2)\n",
        "print(v.shape)\n",
        "print(v3.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l560ng4tyOdG",
        "outputId": "4d115626-f416-4883-a65b-d0b78ad97590"
      },
      "outputs": [],
      "source": [
        "# Now the rows of v match the columns of v3 we can take the dot product\n",
        "np.dot(v, v3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUA1N4pS4-aY"
      },
      "source": [
        "# Let's build our first neural net\n",
        "\n",
        "Load the MNIST library which is part of [Keras](https://keras.io/datasets/).  MNIST stands for [Modified National Institute of Standards and Technology](https://en.wikipedia.org/wiki/MNIST_database). It is a collection of 60,000 training and 10,000 test images of the digits 0-9. We will build a deep learning nerual net model to classify the 10 digits. This is the 'Hello World' problem of deep learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AG-iMB8P3DZ"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Efu6_zaQKtQ"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYu3aOo4Qn9R",
        "outputId": "b35c9346-90d3-43d6-9b1b-2aeef1ce1e00"
      },
      "outputs": [],
      "source": [
        "train_images.shape #60,000 images that are 28 pixels by 28 pixels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73Jt87YRZBXe",
        "outputId": "7f3c51cb-d20f-4d60-e0dc-f344942b8940"
      },
      "outputs": [],
      "source": [
        "train_images.ndim #3D tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_fgMe2h4-bm",
        "outputId": "298b36ef-30dc-4d63-f2f6-ba9d9aa9286f"
      },
      "outputs": [],
      "source": [
        "print('The maximum value in the array is', train_images.max()) # The maximum value in the array is 255\n",
        "print('The minimum value in the array is', train_images.min()) # The minimum value in the array is 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvcS2anBQ8cd",
        "outputId": "f59f0680-1eb8-4050-dbde-7610601fd01c"
      },
      "outputs": [],
      "source": [
        "# Get the shape, dimensions, max and min value of the test images\n",
        "print('test image shape:', test_images.shape)\n",
        "print('number of dimensions:', test_images.ndim)\n",
        "print('maximum value', test_images.max())\n",
        "print('minimum value:', test_images.min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAWThxtY4-co"
      },
      "source": [
        "In general, the first axis in a tensor is the samples, the second axis is height, the third axis is the width, and the fourth is color channels (3 for RGB data, and 1 for black and white). So image data will typically be a 4D tensor -- `[samples, height, width, channels]`, while the MNIST data is 3D because the color channel is black and white and can thus be ignored.\n",
        "Video data will be a 5D tensor -- `[samples, frames, height, width, channels]`. By convention, time series data will be placed on the secod axis when present"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kavsqyWG4-cZ"
      },
      "source": [
        "Let's view one of the images.  We need to import matplotlib to view the digits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwEiakpiZXnf"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "HvYknn0hZf51",
        "outputId": "deb93e07-a93f-4c50-863b-b0003fa18eb7"
      },
      "outputs": [],
      "source": [
        "digit = train_images[4] # Select the fourth sample.\n",
        "plt.imshow(digit, cmap=plt.cm.binary) # Show the sample.  cmap is the color map.  We will keep it black and white (binary)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_eEPRIC9bb1"
      },
      "source": [
        "The 4th train image looks like the number 9.  Lets make sure the label matches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srjlYOAavZUW",
        "outputId": "6c96307b-82f3-41c3-f445-a1ecd1c831e0"
      },
      "outputs": [],
      "source": [
        "train_labels[4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSBcnrgsRPJ3"
      },
      "outputs": [],
      "source": [
        "# Import models and layers from the keras library\n",
        "from keras import models\n",
        "from keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWKxgF2L9_xG"
      },
      "source": [
        "We will be working with sequential models and *dense layers*. More on what those mean later.  Another name for a dense layer is a *fully connected layer*.  The dense layer must be one-dimensional. Therefore, the input image matrix must be reshaped into a vector. There are 60,000 test images with a shape of 28 x 28. We will reshape each image into a vector of length 28 * 28 == 784.\n",
        "\n",
        "We pick the `relu` activation function for our first layer and our output layer activation function is `softmax` because we have a multiclass classification problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8lxhcrHRV0x"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkdeEsM8FztX"
      },
      "source": [
        "Now we compile the model.  We use the `adam` optimizer and choose `categorical_crossentropy` for the loss function because it is a multiclass classification problem. We will evaluate our model accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcixP8_xR5j7",
        "outputId": "41267142-a5d9-4509-fca6-c0893a1dcbd1"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = 'adam',\n",
        "               loss = 'categorical_crossentropy',\n",
        "               metrics = ['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERD4fJuF_n2l"
      },
      "source": [
        "Now the model is built and compiled we need to process the images for the model.  The images need to be reshaped into a vector of the same dimentions as the input shape above.  We also normalize the values of the images to be between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEeckA5ESIMB",
        "outputId": "51a1397d-a6a6-4a7d-9876-d3e7f49660f4"
      },
      "outputs": [],
      "source": [
        "scale_factor = train_images.max()\n",
        "train_images =  train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype('float32')/scale_factor\n",
        "\n",
        "test_images =  test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32')/scale_factor\n",
        "\n",
        "print(train_images.ndim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bw_1wSzI4-ex",
        "outputId": "3cb503cc-30de-4d9c-9d87-f3459df9a818"
      },
      "outputs": [],
      "source": [
        "print('train image shape:', train_images.shape)\n",
        "print('number of dimensions:', train_images.ndim)\n",
        "print('maximum value', train_images.max())\n",
        "print('minimum value:', train_images.min())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "q8QVj91nADix",
        "outputId": "dcc3da81-d636-4539-ff8b-efbfda87eca3"
      },
      "outputs": [],
      "source": [
        "# We can always get our images back by reshaping to a matrix.\n",
        "plt.imshow(train_images.reshape((60000,28,28))[4], cmap=plt.cm.binary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeczsZHUVDQx"
      },
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9u7dxrQGsi8",
        "outputId": "a38133a1-956e-46c9-8b6e-17069c7ec358"
      },
      "outputs": [],
      "source": [
        "# We need to convert the labels into catergorical values.\n",
        "# We can check the train lables for the 4th value to ensure\n",
        "# it is labeled as 9\n",
        "print(train_labels[4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w90ZrgWhVPC1",
        "outputId": "f78ac80b-22ff-4875-98ec-febf3fcd9165"
      },
      "outputs": [],
      "source": [
        "# Batch size is how many images to process at once.\n",
        "# Epoch is how many times to repeat the analysis.\n",
        "# Each epoch performs 500 gradient updates (60,000/120 = 500)\n",
        "model.fit(train_images, train_labels, epochs = 5, batch_size = 120)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHqqd_YYVdz3",
        "outputId": "ff4ed032-6823-4f34-e47c-c24a0eea54a2"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('test_acc:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIRCQyZ2F24o"
      },
      "source": [
        "####  Build 3 different models with a dense layer with `relu` activation.  The output layer activation must be `softmax` since we have a multiclass problem.  You will compile the three different models with different optimizers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgHnMI6T4-f6"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "model_opt = {}\n",
        "for optimizer in ['adam', 'sgd', 'rmsprop']:\n",
        "  model_opt[optimizer] = models.Sequential()\n",
        "  model_opt[optimizer].add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "  model_opt[optimizer].add(layers.Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnUDSgXk4-gE"
      },
      "source": [
        "#### Compile your three models with three different optimizers. Page 89 - 90 of the tetbook list some different optimizers.  You can also find more optimizers and documentation here: https://keras.io/api/optimizers/\n",
        "#### Use `categorical_crossentropy` for loss since this problem is a multiclass classification problem. The metric will be `accuracy`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MG66jz924KwK"
      },
      "source": [
        "| Optimizer | Characteristics | When to Use |\n",
        "|-----------|-----------------|-------------|\n",
        "| **SGD** | - Simple and transparent.<br>- May require more epochs to converge.<br>- Optional momentum accelerates convergence. | - When you have a lot of data and simplicity is preferred.<br>- When finer control over the learning process is needed. |\n",
        "| **Momentum** | - Helps accelerate SGD in the relevant direction.<br>- Can navigate ravines and small local minima better than plain SGD. | - When you want to resolve SGD’s slow convergence in saddle point regions.<br>- In deep networks that suffer from training plateaus. |\n",
        "| **Nesterov Accelerated Gradient (NAG)** | - A variant of momentum.<br>- Looks ahead by calculating the gradient of the future position. | - When you need faster convergence than standard momentum.<br>- In convex or non-convex optimizations. |\n",
        "| **Adagrad** | - Adapts the learning rate to the parameters.<br>- Performs larger updates for infrequent parameters. | - For sparse data (e.g., text data, images with lots of pixels not containing information).<br>- When dealing with non-stationary objectives. |\n",
        "| **Adadelta** | - Addresses Adagrad’s rapidly decreasing learning rates.<br>- Uses a window of accumulated past gradients. | - When you need robustness to large gradients, noise, and architecture choice.<br>- In problems where learning rate should not diminish to infinitesimal values. |\n",
        "| **RMSprop** | - Modifies Adagrad to prevent monotonically decreasing learning rate.<br>- Uses moving average of squared gradients. | - When training recurrent neural networks.<br>- For non-stationary objectives and noisy gradients. |\n",
        "| **Adam** | - Combines benefits of Adagrad and RMSprop.<br>- Uses biased estimates of first and second moments of gradients. | - As a default optimizer, since it's suitable for a wide range of problems.<br>- When you desire an optimizer that requires minimal hyperparameter tuning. |\n",
        "| **Adamax** | - A variant of Adam based on the infinity norm.<br>- More robust to large gradients. | - When gradients are very sparse or problems where Adam's learning rate becomes too small. |\n",
        "| **Nadam** | - Combines NAG and Adam.<br>- Incorporates Nesterov momentum into Adam. | - When you want to leverage the benefits of Nesterov momentum with Adam's adaptive learning rates. |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhHGydeC4-gH"
      },
      "outputs": [],
      "source": [
        "for optimizer in model_opt:\n",
        "  model_opt[optimizer].compile(optimizer=optimizer,\n",
        "                               loss='categorical_crossentropy',\n",
        "                               metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7uSP2vm4-gR"
      },
      "source": [
        "#### Fit the models with epochs = 5 and  batch_size = 150"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9qFLRMA4-gT",
        "outputId": "4cba25d6-9f60-4564-888d-c3832103e6c6"
      },
      "outputs": [],
      "source": [
        "for optimizer in model_opt:\n",
        "  print(f'Fitting model {optimizer}...')\n",
        "  model_opt[optimizer].fit(train_images, train_labels, epochs=5, batch_size=150)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WB4RPCz54-gb"
      },
      "source": [
        "#### Test the accuracy of the model on the test images and test labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7V6DjwV4-gc",
        "outputId": "52747a1a-0eb5-4b7e-eecd-e68506d0422d"
      },
      "outputs": [],
      "source": [
        "best_opt = ''\n",
        "best_acc = 0\n",
        "\n",
        "for opt in model_opt:\n",
        "  model = model_opt[opt]\n",
        "  test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "  print(f'{model} test accuracy: {test_acc}')\n",
        "  if test_acc > best_acc:\n",
        "    best_acc = test_acc\n",
        "    best_opt = opt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbR0ds5G4-gm"
      },
      "source": [
        "# Which optimizer gave the highest accuracy? Write you answer below\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwZba69CNXNu",
        "outputId": "9c75e511-6db2-47fc-82ae-dbe3d25cedcf"
      },
      "outputs": [],
      "source": [
        "print(f'Best optimizer: {best_opt}')\n",
        "print(f'Best accuracy: {best_acc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD5Pjrqpa36e"
      },
      "source": [
        "### Using the optimizer that gave the highest accuracy compile 3 different models with 3 hidden layers and varying units in each hidden layer.  The first  layer is given to you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm99jWdE9fsN",
        "outputId": "fb2c4ac6-7d2f-46a1-9e5c-0075773dce19"
      },
      "outputs": [],
      "source": [
        "model_params = {\n",
        "    'h0_model': [512, 10],\n",
        "    'h1_model': [768, 280, 28, 10],\n",
        "    'h2_model': [512, 280, 28, 10],\n",
        "    'h3_model': [384, 280, 28, 10],\n",
        "}\n",
        "\n",
        "model_selection = {}\n",
        "\n",
        "def create_model(layer_sizes, input_shape=(28 * 28,)):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(layer_sizes[0], activation='relu', input_shape=input_shape))\n",
        "    for size in layer_sizes[1:-1]:\n",
        "        model.add(layers.Dense(size, activation='relu'))\n",
        "    model.add(layers.Dense(layer_sizes[-1], activation='softmax'))\n",
        "    return model\n",
        "\n",
        "for model_name in model_params:\n",
        "  print(model_name)\n",
        "  model = create_model(model_params[model_name])\n",
        "  model_selection[model_name] = model\n",
        "  # print(model.summary())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY-vLrzS4-g1"
      },
      "source": [
        "#### Complie the three models with the best optimizer from above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvYLN-Ld4-g3"
      },
      "outputs": [],
      "source": [
        "# optimizer = best_opt\n",
        "loss = 'categorical_crossentropy'\n",
        "metric = ['accuracy']\n",
        "\n",
        "for model_name in model_selection:\n",
        "  model = model_selection[model_name]\n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.000125)\n",
        "  model.compile(optimizer=optimizer, loss=loss, metrics=metric)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRMZ56yI4-hF"
      },
      "source": [
        "#### Fit the models with epochs = 5 and  batch_size = 120"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wO_mcJ9x4-hI",
        "outputId": "842392cd-6e92-462b-f516-6e62ae40e4d6"
      },
      "outputs": [],
      "source": [
        "model_history = {}\n",
        "# callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\n",
        "for model_name in model_selection:\n",
        "  model = model_selection[model_name]\n",
        "  print(f'Fitting model {model_name}...')\n",
        "  history = model.fit(train_images, train_labels, epochs=5, batch_size=120, verbose=0)\n",
        "  model_history[model_name] = history\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_history(history):\n",
        "    fig, ax = plt.subplots(figsize=(8, 4))\n",
        "    ax.set_title('Epochs vs Loss and Accuracy')\n",
        "    \n",
        "    ax.plot(history.history['loss'], label='Loss', color='r')\n",
        "    ax.legend()\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('Loss')\n",
        "    \n",
        "    ax2 = ax.twinx()\n",
        "    ax2.plot(history.history['accuracy'], label='Accuracy')\n",
        "    ax2.legend()\n",
        "    ax2.set_ylabel('Accuracy')\n",
        "\n",
        "    ax.grid(True)\n",
        "    ax.xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "#for model_name in model_history:\n",
        "#    plot_history(model_history[model_name])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0Kcmj6x4-hU"
      },
      "source": [
        "#### Test the accuracy of the 3 models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRUw9R5F4-ha",
        "outputId": "134be87c-9630-4278-d5d3-893ee7fbe85e"
      },
      "outputs": [],
      "source": [
        "best_acc = 0\n",
        "best_model = ''\n",
        "\n",
        "for model_name in model_selection:\n",
        "  model = model_selection[model_name]\n",
        "  test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "  print(f'{model_name} test accuracy: {test_acc}')\n",
        "\n",
        "  if test_acc > best_acc:\n",
        "    best_acc = test_acc\n",
        "    best_model = model_name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-fHqdpQ4-hm"
      },
      "source": [
        "#### Which model gave the highest accuracy? Write you answer below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YVyf_1RElXR",
        "outputId": "6449c293-5777-49f5-c3df-dcc09b7926eb"
      },
      "outputs": [],
      "source": [
        "print(f'The model with the highest accuracy is {best_model} with an accuracy of {best_acc}')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "2-fHqdpQ4-hm"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
